from __future__ import annotations

from datetime import datetime, timezone
from typing import Any, Dict, Optional, Sequence

import numpy as np
import pandas as pd
from pymongo import ASCENDING, MongoClient

from config import Config


class AnalysisQueryResultStore:
    """
    Persist joined query results generated by an analysis plan.

    Documents are keyed by ``plan_id`` so re-running the same plan overwrites
    the existing record instead of creating duplicates.
    """

    def __init__(
        self,
        db_client: Optional[MongoClient] = None,
        collection_name: str = "analysis_query_results",
    ) -> None:
        self._client = db_client or MongoClient(Config.MONGO_URI)
        self._db = self._client[Config.DATABASE_NAME]
        self.collection = self._db[collection_name]
        self._ensure_indexes()

    def _ensure_indexes(self) -> None:
        """
        Create indexes that enforce uniqueness per analysis plan and
        support querying recent executions.
        """
        self.collection.create_index([("plan_id", ASCENDING)], unique=True)
        self.collection.create_index("updated_at")

    def save_joined_results(
        self,
        *,
        plan_id: str,
        plan_name: Optional[str],
        join_columns: Sequence[str],
        join_strategy: str,
        query_specs: Sequence[Dict[str, Any]],
        dataframe: pd.DataFrame,
        analysis_summary: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Persist the fully joined DataFrame plus any analytical summaries.

        Returns the document payload that was written to MongoDB.
        """
        if not plan_id:
            raise ValueError("plan_id is required to store analysis results.")

        rows = dataframe.to_dict(orient="records")
        document = {
            "plan_id": plan_id,
            "plan_name": plan_name,
            "record_count": int(len(dataframe)),
            "columns": list(dataframe.columns),
            "join_columns": list(join_columns),
            "join_strategy": join_strategy,
            "queries": self._sanitize(query_specs),
            "results": self._sanitize(rows),
            "analysis_summary": self._sanitize(analysis_summary or {}),
            "metadata": self._sanitize(metadata or {}),
            "updated_at": datetime.now(timezone.utc),
        }

        self.collection.update_one(
            {"plan_id": plan_id},
            {"$set": document},
            upsert=True,
        )
        return document

    def _sanitize(self, value: Any) -> Any:
        """
        Convert pandas/numpy objects into BSON-friendly native Python types.
        """
        if isinstance(value, dict):
            return {k: self._sanitize(v) for k, v in value.items()}

        if isinstance(value, (list, tuple)):
            converted = [self._sanitize(v) for v in value]
            return converted if isinstance(value, list) else tuple(converted)

        if isinstance(value, (np.integer,)):
            return int(value)

        if isinstance(value, (np.floating,)):
            return float(value)

        if isinstance(value, (np.bool_,)):
            return bool(value)

        if isinstance(value, (np.ndarray,)):
            return [self._sanitize(v) for v in value.tolist()]

        if isinstance(value, (pd.Timestamp,)):
            return value.to_pydatetime()

        if isinstance(value, (pd.Series, pd.Index)):
            return [self._sanitize(v) for v in value.tolist()]

        return value
